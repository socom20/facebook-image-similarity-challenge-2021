{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b279635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Found: 861 screenshots.  SCREENSHOT_DIR=./FB_page_qry\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gc\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "from collections import OrderedDict, namedtuple\n",
    "import multiprocessing\n",
    "import threading\n",
    "import traceback\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torchmetrics\n",
    "import pl_bolts\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import faiss\n",
    "\n",
    "from modules.AugsDS_v7 import *\n",
    "from modules.eval_functions import *\n",
    "from modules.eval_metrics import evaluate\n",
    "\n",
    "sys.path.append('./modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18a90bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.Facebook_model_v20 import ArgsT19_EffNetV2S_ImageNet, FacebookModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3862d834",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = = = = = = = = = = ArgList = = = = = = = = = =\n",
      "ALL_FOLDERS                   : ['query_images', 'reference_images', 'training_images', 'imagenet_images']\n",
      "BATCH_SIZE                    : 64\n",
      "DATASET_WH                    : (384, 384)\n",
      "DS_DIR                        : ./all_datasets/dataset_jpg_384x384\n",
      "DS_INPUT_DIR                  : ./all_datasets/dataset\n",
      "GeM_opt_p                     : True\n",
      "GeM_p                         : 3.0\n",
      "ImgNet_SAMPLES                : ./data/ImageNet_samples_v.pickle\n",
      "N_GPUS                        : 1\n",
      "N_WORKERS                     : 8\n",
      "OUTPUT_WH                     : (224, 224)\n",
      "accelerator                   : ddp\n",
      "arc_bottleneck                : None\n",
      "arc_classnum                  : 1200000\n",
      "arc_gamma                     : 3.0\n",
      "arc_m                         : 0.4\n",
      "arc_s                         : 40.0\n",
      "backbone_name                 : efficientnetv2_rw_s\n",
      "checkpoint_base_path          : ./TEST19_ArcF_ImgNet\n",
      "clip_grad_norm                : 1.0\n",
      "criterion_name                : arcface\n",
      "do_ref_trn                    : False\n",
      "duplicate_backbone            : False\n",
      "duplicate_neck                : False\n",
      "embedding_size                : 384\n",
      "eps                           : 1e-06\n",
      "img_norm_type                 : imagenet\n",
      "init_lr                       : 0.001\n",
      "lr_prop                       : 0.001\n",
      "model_name                    : arc_model\n",
      "model_resolution              : (224, 224)\n",
      "n_decay_epochs                : 100\n",
      "n_steps_grad_update           : 1\n",
      "n_warmup_epochs               : 4\n",
      "neck_type                     : A\n",
      "optimizer_name                : adam\n",
      "precision                     : 16\n",
      "pretrained_bb                 : False\n",
      "ref_trn_n_epochs              : 5\n",
      "sched_factor                  : 0.5\n",
      "sched_patience                : 3\n",
      "scheduler_name                : LinearWarmupCosineAnnealingLR\n",
      "seed                          : 1732\n",
      "start_ckpt                    : None\n",
      "use_GeM                       : True\n",
      "use_scheduler                 : True\n",
      "weight_decay                  : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = ArgsT19_EffNetV2S_ImageNet()\n",
    "\n",
    "args.pretrained_bb = False\n",
    "print(args) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3d4eb9",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c935e1d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Total weights: 483.64M\n"
     ]
    }
   ],
   "source": [
    "model = FacebookModel(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5074ce31",
   "metadata": {},
   "source": [
    "# Loading ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795b7e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Restored checkpoint: ./checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893.ckpt.\n"
     ]
    }
   ],
   "source": [
    "ckpt_filename = './checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893.ckpt'\n",
    "_ = model.restore_checkpoint(ckpt_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd4698",
   "metadata": {},
   "source": [
    "# Inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7b0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_simple_augmentation = False\n",
    "K = 500\n",
    "\n",
    "BATCH_SIZE   = 128\n",
    "N_WORKERS    = 7\n",
    "DS_INPUT_DIR = f'./all_datasets/dataset'\n",
    "ALL_FOLDERS  = ['query_images', 'reference_images', 'training_images']\n",
    "\n",
    "args.ALL_FOLDERS = ALL_FOLDERS\n",
    "args.BATCH_SIZE = BATCH_SIZE\n",
    "args.N_WORKERS = N_WORKERS\n",
    "args.DS_INPUT_DIR = DS_INPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4c59cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while DS_INPUT_DIR[-1] in ['/', r'\\\\']:\n",
    "    DS_INPUT_DIR = DS_INPUT_DIR[:-1]\n",
    "    \n",
    "# Path where the rescaled images will be saved\n",
    "args.DS_DIR = f'{args.DS_INPUT_DIR}_jpg_{args.DATASET_WH[0]}x{args.DATASET_WH[1]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bea29c",
   "metadata": {},
   "source": [
    "# Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8208c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths:\n",
      " - DS_INPUT_DIR: ./all_datasets/dataset\n",
      " - DS_DIR:       ./all_datasets/dataset_jpg_384x384\n"
     ]
    }
   ],
   "source": [
    "if any( [not os.path.exists(os.path.join(args.DS_DIR, folder)) for folder in args.ALL_FOLDERS] ):\n",
    "    assert os.path.exists(args.DS_INPUT_DIR), f'DS_INPUT_DIR not found: {args.DS_INPUT_DIR}'\n",
    "\n",
    "    resize_dataset(\n",
    "        ds_input_dir=args.DS_INPUT_DIR,\n",
    "        ds_output_dir=args.DS_DIR,\n",
    "        output_wh=args.DATASET_WH,\n",
    "        output_ext='jpg',\n",
    "        num_workers=args.N_WORKERS,\n",
    "        ALL_FOLDERS=args.ALL_FOLDERS,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "print('Paths:')\n",
    "print(' - DS_INPUT_DIR:', args.DS_INPUT_DIR)\n",
    "print(' - DS_DIR:      ', args.DS_DIR)\n",
    "\n",
    "assert os.path.exists(args.DS_DIR), f'DS_DIR not found: {args.DS_DIR}'\n",
    "\n",
    "try:\n",
    "    public_ground_truth_path = os.path.join(args.DS_DIR, 'public_ground_truth.csv')\n",
    "    public_gt = pd.read_csv( public_ground_truth_path)\n",
    "\n",
    "except:\n",
    "    public_ground_truth_path = os.path.join(args.DS_INPUT_DIR, 'public_ground_truth.csv')\n",
    "    public_gt = pd.read_csv( public_ground_truth_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa328b1",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1d2421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/albumentations/augmentations/transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_qry_full = FacebookDataset(\n",
    "    samples_id_v=[f'Q{i:05d}' for i in range(50_000)],\n",
    "    do_augmentation=False,\n",
    "    ds_dir=args.DS_DIR,\n",
    "    output_wh=args.OUTPUT_WH,\n",
    "    channel_first=True,\n",
    "    norm_type= args.img_norm_type,\n",
    "    verbose=True,\n",
    ")\n",
    "# ds_qry_full.plot_sample(4)\n",
    "\n",
    "\n",
    "ds_ref_full = FacebookDataset(\n",
    "    samples_id_v=[f'R{i:06d}' for i in range(1_000_000)],\n",
    "    do_augmentation=False,\n",
    "    ds_dir=args.DS_DIR,\n",
    "    output_wh=args.OUTPUT_WH,\n",
    "    channel_first=True,\n",
    "    norm_type=args.img_norm_type,\n",
    "    verbose=True,\n",
    ")\n",
    "# ds_ref_full.plot_sample(4)\n",
    "\n",
    "\n",
    "ds_trn_full = FacebookDataset(\n",
    "    samples_id_v=[f'T{i:06d}' for i in range(1_000_000)],\n",
    "    do_augmentation=False,\n",
    "    ds_dir=args.DS_DIR,\n",
    "    output_wh=args.OUTPUT_WH,\n",
    "    channel_first=True,\n",
    "    norm_type=args.img_norm_type,\n",
    "    verbose=True,\n",
    ")\n",
    "# ds_trn_full.plot_sample(4)\n",
    "\n",
    "\n",
    "\n",
    "dl_qry_full = DataLoader(\n",
    "        ds_qry_full,\n",
    "        batch_size=args.BATCH_SIZE,\n",
    "        num_workers=args.N_WORKERS,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "dl_ref_full = DataLoader(\n",
    "    ds_ref_full,\n",
    "    batch_size=args.BATCH_SIZE,\n",
    "    num_workers=args.N_WORKERS,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "dl_trn_full = DataLoader(\n",
    "    ds_trn_full,\n",
    "    batch_size=args.BATCH_SIZE,\n",
    "    num_workers=args.N_WORKERS,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209abb92",
   "metadata": {},
   "source": [
    "### Query embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f67b590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 391/391 [01:38<00:00,  3.98it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_qry_d = calc_embed_d(\n",
    "    model, \n",
    "    dataloader=dl_qry_full,\n",
    "    do_simple_augmentation=do_simple_augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf7c6c",
   "metadata": {},
   "source": [
    "### Reference embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d183470",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = '_AUG' if do_simple_augmentation else ''\n",
    "submission_path = ckpt_filename.replace('.ckpt', f'_{args.OUTPUT_WH[0]}x{args.OUTPUT_WH[1]}{aug}_REF.h5')\n",
    "scores_path = submission_path.replace('.h5', '_match_d.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435154a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7813/7813 [30:34<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saved: ./checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893_224x224_REF.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [06:09<00:00,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893_224x224_REF_match_d.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed_ref_d = calc_embed_d(\n",
    "    model, \n",
    "    dataloader=dl_ref_full, \n",
    "    do_simple_augmentation=do_simple_augmentation\n",
    ")\n",
    "\n",
    "save_submission(\n",
    "    embed_qry_d,\n",
    "    embed_ref_d,\n",
    "    save_path=submission_path,\n",
    ")\n",
    "\n",
    "match_d = calc_match_scores(embed_qry_d, embed_ref_d, k=K)\n",
    "save_obj(match_d, scores_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b77b86b",
   "metadata": {},
   "source": [
    "### Public GT validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "781a0091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893_224x224_REF.h5\n",
      "{\n",
      "  \"average_precision\": 0.6378110962890179,\n",
      "  \"recall_p90\": 0.5223402123822881\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "eval_d = evaluate(\n",
    "    submission_path=submission_path,\n",
    "    gt_path=public_ground_truth_path,\n",
    "    is_matching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3704e",
   "metadata": {},
   "source": [
    "### Training embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7cda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = '_AUG' if do_simple_augmentation else ''\n",
    "submission_path = ckpt_filename.replace('.ckpt', f'_{args.OUTPUT_WH[0]}x{args.OUTPUT_WH[1]}{aug}_TRN.h5')\n",
    "scores_path = submission_path.replace('.h5', '_match_d.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17842563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7813/7813 [31:35<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saved: ./checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893_224x224_TRN.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                       | 1/100 [02:13<3:39:41, 133.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28787/2965686489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmatch_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_match_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_trn_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_ref_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle/Facebook/facebook-zip/modules/eval_functions.py\u001b[0m in \u001b[0;36mcalc_match_scores\u001b[0;34m(embed_qry_d, embed_ref_d, k, steps)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mi_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi_s\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m  \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0membed_qry_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_e\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mD_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/faiss/__init__.py\u001b[0m in \u001b[0;36mreplacement_search\u001b[0;34m(self, x, k, D, I)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/faiss/swigfaiss.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, n, x, k, distances, labels)\u001b[0m\n\u001b[1;32m   2170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndexFlat_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrange_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_trn_d = calc_embed_d(\n",
    "    model, \n",
    "    dataloader=dl_trn_full, \n",
    "    do_simple_augmentation=do_simple_augmentation\n",
    ")\n",
    "\n",
    "save_submission(\n",
    "    embed_qry_d,\n",
    "    embed_trn_d,\n",
    "    save_path=submission_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9003ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [06:19<00:00,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./checkpoints/smp_test19/FacebookModel_Eepoch=67_TLtrn_loss_epoch=0.9913_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=0.4815_VAval_acc_epoch=0.9893_224x224_TRN_match_d.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "match_d = calc_match_scores(embed_qry_d, embed_trn_d, k=K)\n",
    "save_obj(match_d, scores_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647dd9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
