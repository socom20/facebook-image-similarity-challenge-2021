{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9bc4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Found: 861 screenshots.  SCREENSHOT_DIR=./FB_page_qry\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gc\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "from collections import OrderedDict, namedtuple\n",
    "import multiprocessing\n",
    "import threading\n",
    "import traceback\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn, optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torchmetrics\n",
    "import pl_bolts\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import faiss\n",
    "\n",
    "from modules.AugsDS_v7 import *\n",
    "from modules.eval_functions import *\n",
    "from modules.eval_metrics import evaluate\n",
    "\n",
    "sys.path.append('./modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae1a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.Facebook_model_AFMultiGPU_v22 import ArgsT22_EffNetV2, FacebookModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6896c27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = = = = = = = = = = ArgList = = = = = = = = = =\n",
      "ALL_FOLDERS                   : ['query_images', 'reference_images', 'training_images', 'imagenet_images', 'face_frames']\n",
      "BACKBONE_GPUS                 : [0]\n",
      "BATCH_SIZE                    : 96\n",
      "DATASET_WH                    : (384, 384)\n",
      "DS_DIR                        : ./all_datasets/dataset_jpg_384x384\n",
      "DS_INPUT_DIR                  : ./all_datasets/dataset\n",
      "FrmFaces_SAMPLES              : ./FrameFaces_samples_v.pickle\n",
      "GeM_opt_p                     : True\n",
      "GeM_p                         : 3.0\n",
      "ImgNet_SAMPLES                : ./ImageNet_samples_v.pickle\n",
      "N_WORKERS                     : 28\n",
      "OUTPUT_WH                     : (160, 160)\n",
      "accelerator                   : ddp\n",
      "arc_bottleneck                : None\n",
      "arc_classnum                  : 40\n",
      "arc_devices_v                 : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "arc_m                         : 0.4\n",
      "arc_optimizer                 : None\n",
      "arc_s                         : 40.0\n",
      "arc_w_prop_v                  : None\n",
      "arc_weight_decay              : 0.0\n",
      "backbone_name                 : efficientnetv2_rw_s\n",
      "checkpoint_base_path          : ./TEST23_MiltiGPU_AF\n",
      "clip_grad_norm                : 1.0\n",
      "criterion_name                : arcface_multigpu\n",
      "do_ref_trn                    : False\n",
      "embedding_size                : 256\n",
      "eps                           : 1e-06\n",
      "img_norm_type                 : imagenet\n",
      "init_lr                       : 0.001\n",
      "lr_prop                       : 0.001\n",
      "model_name                    : arc_model\n",
      "model_resolution              : (160, 160)\n",
      "n_decay_epochs                : 100\n",
      "n_facebook_samples            : 1000000\n",
      "n_frm_face_samples            : 0\n",
      "n_imagenet_samples            : 1000000\n",
      "n_steps_grad_update           : 1\n",
      "n_warmup_epochs               : 4\n",
      "neck_type                     : A\n",
      "optimizer_name                : adam\n",
      "precision                     : 16\n",
      "pretrained_bb                 : False\n",
      "ref_trn_n_epochs              : 5\n",
      "sched_factor                  : 0.5\n",
      "sched_patience                : 3\n",
      "scheduler_name                : LinearWarmupCosineAnnealingLR\n",
      "seed                          : None\n",
      "start_ckpt                    : None\n",
      "use_GeM                       : True\n",
      "use_scheduler                 : True\n",
      "weight_decay                  : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = ArgsT22_EffNetV2()\n",
    "\n",
    "args.pretrained_bb = False\n",
    "\n",
    "args.arc_classnum = 40\n",
    "print(args) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e671fb7",
   "metadata": {},
   "source": [
    "# Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac38ff16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Total weights: 22.62M\n"
     ]
    }
   ],
   "source": [
    "model = FacebookModel(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb2f3d",
   "metadata": {},
   "source": [
    "# Loading ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d12547e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Loading model state_dict.\n",
      " - Restored checkpoint: ./checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " - WARNING: shapes mismatch in \"criterion.kernel_v.0\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.1\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.2\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.3\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.4\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.5\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.6\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.7\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.8\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.9\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.10\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.11\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.12\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.13\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.14\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.15\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.16\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.17\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.18\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.19\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.20\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.21\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.22\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.23\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.24\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.25\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.26\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.27\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.28\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.29\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.30\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.31\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.32\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.33\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.34\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.35\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.36\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.37\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.38\": (256, 50000) vs (256, 1). Weights will not be loaded.\n",
      " - WARNING: shapes mismatch in \"criterion.kernel_v.39\": (256, 50000) vs (256, 1). Weights will not be loaded.\n"
     ]
    }
   ],
   "source": [
    "ckpt_filename = './checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752.ckpt'\n",
    "_ = model.restore_checkpoint(ckpt_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534c9f8",
   "metadata": {},
   "source": [
    "# Inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268893b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_simple_augmentation = False\n",
    "K = 500\n",
    "\n",
    "BATCH_SIZE   = 128\n",
    "N_WORKERS    = 7\n",
    "DS_INPUT_DIR = f'./all_datasets/dataset'\n",
    "ALL_FOLDERS  = ['query_images', 'reference_images', 'training_images']\n",
    "\n",
    "args.ALL_FOLDERS = ALL_FOLDERS\n",
    "args.BATCH_SIZE = BATCH_SIZE\n",
    "args.N_WORKERS = N_WORKERS\n",
    "args.DS_INPUT_DIR = DS_INPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "888f33a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "while DS_INPUT_DIR[-1] in ['/', r'\\\\']:\n",
    "    DS_INPUT_DIR = DS_INPUT_DIR[:-1]\n",
    "    \n",
    "# Path where the rescaled images will be saved\n",
    "args.DS_DIR = f'{args.DS_INPUT_DIR}_jpg_{args.DATASET_WH[0]}x{args.DATASET_WH[1]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db79a0",
   "metadata": {},
   "source": [
    "# Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52bf221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths:\n",
      " - DS_INPUT_DIR: ./all_datasets/dataset\n",
      " - DS_DIR:       ./all_datasets/dataset_jpg_384x384\n"
     ]
    }
   ],
   "source": [
    "if any( [not os.path.exists(os.path.join(args.DS_DIR, folder)) for folder in args.ALL_FOLDERS] ):\n",
    "    assert os.path.exists(args.DS_INPUT_DIR), f'DS_INPUT_DIR not found: {args.DS_INPUT_DIR}'\n",
    "\n",
    "    resize_dataset(\n",
    "        ds_input_dir=args.DS_INPUT_DIR,\n",
    "        ds_output_dir=args.DS_DIR,\n",
    "        output_wh=args.DATASET_WH,\n",
    "        output_ext='jpg',\n",
    "        num_workers=args.N_WORKERS,\n",
    "        ALL_FOLDERS=args.ALL_FOLDERS,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "print('Paths:')\n",
    "print(' - DS_INPUT_DIR:', args.DS_INPUT_DIR)\n",
    "print(' - DS_DIR:      ', args.DS_DIR)\n",
    "\n",
    "assert os.path.exists(args.DS_DIR), f'DS_DIR not found: {args.DS_DIR}'\n",
    "\n",
    "try:\n",
    "    public_ground_truth_path = os.path.join(args.DS_DIR, 'public_ground_truth.csv')\n",
    "    public_gt = pd.read_csv( public_ground_truth_path)\n",
    "\n",
    "except:\n",
    "    public_ground_truth_path = os.path.join(args.DS_INPUT_DIR, 'public_ground_truth.csv')\n",
    "    public_gt = pd.read_csv( public_ground_truth_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2af6e7",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9423771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/albumentations/augmentations/transforms.py:688: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds_qry_full = FacebookDataset(\n",
    "    samples_id_v=[f'Q{i:05d}' for i in range(50_000)],\n",
    "    do_augmentation=False,\n",
    "    ds_dir=args.DS_DIR,\n",
    "    output_wh=args.OUTPUT_WH,\n",
    "    channel_first=True,\n",
    "    norm_type= args.img_norm_type,\n",
    "    verbose=True,\n",
    ")\n",
    "# ds_qry_full.plot_sample(4)\n",
    "\n",
    "\n",
    "ds_ref_full = FacebookDataset(\n",
    "    samples_id_v=[f'R{i:06d}' for i in range(1_000_000)],\n",
    "    do_augmentation=False,\n",
    "    ds_dir=args.DS_DIR,\n",
    "    output_wh=args.OUTPUT_WH,\n",
    "    channel_first=True,\n",
    "    norm_type=args.img_norm_type,\n",
    "    verbose=True,\n",
    ")\n",
    "# ds_ref_full.plot_sample(4)\n",
    "\n",
    "\n",
    "ds_trn_full = FacebookDataset(\n",
    "    samples_id_v=[f'T{i:06d}' for i in range(1_000_000)],\n",
    "    do_augmentation=False,\n",
    "    ds_dir=args.DS_DIR,\n",
    "    output_wh=args.OUTPUT_WH,\n",
    "    channel_first=True,\n",
    "    norm_type=args.img_norm_type,\n",
    "    verbose=True,\n",
    ")\n",
    "# ds_trn_full.plot_sample(4)\n",
    "\n",
    "\n",
    "\n",
    "dl_qry_full = DataLoader(\n",
    "        ds_qry_full,\n",
    "        batch_size=args.BATCH_SIZE,\n",
    "        num_workers=args.N_WORKERS,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "dl_ref_full = DataLoader(\n",
    "    ds_ref_full,\n",
    "    batch_size=args.BATCH_SIZE,\n",
    "    num_workers=args.N_WORKERS,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "dl_trn_full = DataLoader(\n",
    "    ds_trn_full,\n",
    "    batch_size=args.BATCH_SIZE,\n",
    "    num_workers=args.N_WORKERS,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be415d",
   "metadata": {},
   "source": [
    "### Query embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c15c23a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Setting Backbone's device: cuda:0\n",
      " - ArcfaceMultiGPU, setting devices:\n",
      "  |-> kernel( 0): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 1): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 2): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 3): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 4): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 5): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 6): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 7): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 8): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 9): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(10): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(11): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(12): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(13): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(14): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(15): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(16): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(17): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(18): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(19): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(20): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(21): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(22): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(23): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(24): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(25): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(26): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(27): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(28): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(29): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(30): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(31): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(32): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(33): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(34): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(35): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(36): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(37): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(38): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(39): cuda:0   shape: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 391/391 [00:58<00:00,  6.69it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_qry_d = calc_embed_d(\n",
    "    model, \n",
    "    dataloader=dl_qry_full,\n",
    "    do_simple_augmentation=do_simple_augmentation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b73fb5",
   "metadata": {},
   "source": [
    "### Reference embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c159c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = '_AUG' if do_simple_augmentation else ''\n",
    "submission_path = ckpt_filename.replace('.ckpt', f'_{args.OUTPUT_WH[0]}x{args.OUTPUT_WH[1]}{aug}_REF.h5')\n",
    "scores_path = submission_path.replace('.h5', '_match_d.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8578ddaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Setting Backbone's device: cuda:0\n",
      " - ArcfaceMultiGPU, setting devices:\n",
      "  |-> kernel( 0): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 1): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 2): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 3): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 4): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 5): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 6): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 7): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 8): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 9): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(10): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(11): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(12): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(13): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(14): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(15): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(16): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(17): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(18): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(19): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(20): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(21): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(22): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(23): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(24): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(25): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(26): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(27): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(28): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(29): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(30): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(31): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(32): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(33): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(34): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(35): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(36): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(37): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(38): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(39): cuda:0   shape: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7813/7813 [18:15<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saved: ./checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752_160x160_REF.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [04:16<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752_160x160_REF_match_d.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embed_ref_d = calc_embed_d(\n",
    "    model, \n",
    "    dataloader=dl_ref_full, \n",
    "    do_simple_augmentation=do_simple_augmentation\n",
    ")\n",
    "\n",
    "save_submission(\n",
    "    embed_qry_d,\n",
    "    embed_ref_d,\n",
    "    save_path=submission_path,\n",
    ")\n",
    "\n",
    "match_d = calc_match_scores(embed_qry_d, embed_ref_d, k=K)\n",
    "save_obj(match_d, scores_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd70bd",
   "metadata": {},
   "source": [
    "### Public GT validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fcef684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752_160x160_REF.h5\n",
      "{\n",
      "  \"average_precision\": 0.6306082181957473,\n",
      "  \"recall_p90\": 0.5283510318573432\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "eval_d = evaluate(\n",
    "    submission_path=submission_path,\n",
    "    gt_path=public_ground_truth_path,\n",
    "    is_matching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8eca14",
   "metadata": {},
   "source": [
    "### Training embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbec3ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = '_AUG' if do_simple_augmentation else ''\n",
    "submission_path = ckpt_filename.replace('.ckpt', f'_{args.OUTPUT_WH[0]}x{args.OUTPUT_WH[1]}{aug}_TRN.h5')\n",
    "scores_path = submission_path.replace('.h5', '_match_d.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a4ef64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Setting Backbone's device: cuda:0\n",
      " - ArcfaceMultiGPU, setting devices:\n",
      "  |-> kernel( 0): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 1): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 2): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 3): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 4): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 5): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 6): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 7): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 8): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel( 9): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(10): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(11): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(12): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(13): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(14): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(15): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(16): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(17): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(18): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(19): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(20): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(21): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(22): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(23): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(24): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(25): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(26): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(27): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(28): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(29): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(30): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(31): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(32): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(33): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(34): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(35): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(36): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(37): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(38): cuda:0   shape: torch.Size([256, 1])\n",
      "  |-> kernel(39): cuda:0   shape: torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 7813/7813 [18:06<00:00,  7.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Saved: ./checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752_160x160_TRN.h5\n"
     ]
    }
   ],
   "source": [
    "embed_trn_d = calc_embed_d(\n",
    "    model, \n",
    "    dataloader=dl_trn_full, \n",
    "    do_simple_augmentation=do_simple_augmentation\n",
    ")\n",
    "\n",
    "save_submission(\n",
    "    embed_qry_d,\n",
    "    embed_trn_d,\n",
    "    save_path=submission_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f44bc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [04:17<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./checkpoints/smp_test22/FacebookModel_Eepoch=15_TLtrn_loss_epoch=2.1522_TAtrn_acc_epoch=0.0000_VLval_loss_epoch=nan_VAval_acc_epoch=0.9752_160x160_TRN_match_d.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "match_d = calc_match_scores(embed_qry_d, embed_trn_d, k=K)\n",
    "save_obj(match_d, scores_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
